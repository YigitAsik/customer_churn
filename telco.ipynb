{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbacadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# LIBRARIES\n",
    "###################\n",
    "\n",
    "import joblib\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use(\"Qt5Agg\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 170)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170dfd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score, cross_validate, RandomizedSearchCV, validation_curve, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04585a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# FUNCTIONS\n",
    "###################\n",
    "\n",
    "\n",
    "def standart_scaler(col_name):\n",
    "    return (col_name - col_name.mean()) / col_name.std()\n",
    "\n",
    "def check_df(dataframe, head=5):\n",
    "    print(\"##################### Shape #####################\")\n",
    "    print(dataframe.shape)\n",
    "    print(\"##################### Types #####################\")\n",
    "    print(dataframe.dtypes)\n",
    "    print(\"##################### Head #####################\")\n",
    "    print(dataframe.head(head))\n",
    "    print(\"##################### Tail #####################\")\n",
    "    print(dataframe.tail(head))\n",
    "    print(\"##################### NA #####################\")\n",
    "    print(dataframe.isnull().sum())\n",
    "    print(\"##################### Quantiles #####################\")\n",
    "    print(dataframe.describe([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n",
    "\n",
    "def cat_summary(dataframe, col_name, plot=False):\n",
    "\n",
    "    if dataframe[col_name].dtypes == \"bool\":\n",
    "        dataframe[col_name] = dataframe[col_name].astype(int)\n",
    "\n",
    "        print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n",
    "                            \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n",
    "        print(\"##########################################\")\n",
    "\n",
    "        if plot:\n",
    "            sns.countplot(x=dataframe[col_name], data=dataframe)\n",
    "            plt.show(block=True)\n",
    "    else:\n",
    "        print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n",
    "                            \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n",
    "        print(\"##########################################\")\n",
    "\n",
    "        if plot:\n",
    "            sns.countplot(x=dataframe[col_name], data=dataframe)\n",
    "            plt.show(block=True)\n",
    "\n",
    "def num_summary(dataframe, numerical_col, plot=False):\n",
    "    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n",
    "    print(dataframe[numerical_col].describe(quantiles).T)\n",
    "\n",
    "    if plot:\n",
    "        dataframe[numerical_col].hist()\n",
    "        plt.xlabel(numerical_col)\n",
    "        plt.title(numerical_col)\n",
    "        plt.show(block=True)\n",
    "\n",
    "def grab_col_names(dataframe, cat_th=10,  car_th=20):\n",
    "    \"\"\"\n",
    "    Veri setindeki kategorik, numerik ve kategorik fakat kardinal değişkenlerin isimlerini verir.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: dataframe\n",
    "        değişken isimleri alınmak istenen dataframe'dir.\n",
    "    cat_th: int, float\n",
    "        numerik fakat kategorik olan değişkenler için sınıf eşik değeri\n",
    "    car_th: int, float\n",
    "        kategorik fakat kardinal değişkenler için sınıf eşik değeri\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cat_cols: list\n",
    "        Kategorik değişken listesi\n",
    "    num_cols: list\n",
    "        Numerik değişken listesi\n",
    "    cat_but_car: list\n",
    "        Kategorik görünümlü kardinal değişken listesi\n",
    "\n",
    "    Notes\n",
    "    ------\n",
    "    cat_cols + num_cols + cat_but_car = toplam değişken sayısı\n",
    "    num_but_cat cat_cols'un içerisinde.\n",
    "\n",
    "    \"\"\"\n",
    "    # cat_cols, cat_but_car\n",
    "    cat_cols = [col for col in dataframe.columns if str(dataframe[col].dtypes) in [\"category\", \"object\", \"bool\"]]\n",
    "\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < 10 and dataframe[col].dtypes in [\"int\", \"float\"]]\n",
    "\n",
    "    cat_but_car = [col for col in dataframe.columns if\n",
    "                   dataframe[col].nunique() > 20 and str(dataframe[col].dtypes) in [\"category\", \"object\"]]\n",
    "\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes in [\"int\", \"float\"]]\n",
    "    num_cols = [col for col in num_cols if col not in cat_cols]\n",
    "\n",
    "    print(f\"Observations: {dataframe.shape[0]}\")\n",
    "    print(f\"Variables: {dataframe.shape[1]}\")\n",
    "    print(f'cat_cols: {len(cat_cols)}')\n",
    "    print(f'num_cols: {len(num_cols)}')\n",
    "    print(f'cat_but_car: {len(cat_but_car)}')\n",
    "    print(f'num_but_cat: {len(num_but_cat)}')\n",
    "\n",
    "    return cat_cols, num_cols, cat_but_car\n",
    "\n",
    "def target_summary_with_cat(dataframe, target, categorical_col):\n",
    "    print(pd.DataFrame({\"TARGET_MEAN\": dataframe.groupby(categorical_col)[target].mean(),\n",
    "                        \"Count\": dataframe[categorical_col].value_counts(),\n",
    "                        \"Ratio\": 100 * dataframe[categorical_col].value_counts() / len(dataframe)}), end=\"\\n\\n\\n\")\n",
    "\n",
    "def target_summary_with_num(dataframe, target, numerical_col):\n",
    "    print(dataframe.groupby(target).agg({numerical_col: \"mean\"}), end=\"\\n\\n\\n\")\n",
    "\n",
    "def high_correlated_cols(dataframe, plot=False, corr_th=0.90):\n",
    "    corr = dataframe.corr()\n",
    "    cor_matrix = corr.abs()\n",
    "    upper_triangle_matrix = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(bool))\n",
    "    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]\n",
    "    if plot:\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "        sns.set(rc={'figure.figsize': (15, 15)})\n",
    "        sns.heatmap(corr, cmap=\"RdBu\")\n",
    "        plt.show()\n",
    "    return drop_list\n",
    "\n",
    "def outlier_thresholds(dataframe, variable):\n",
    "    quartile1 = dataframe[variable].quantile(0.01)\n",
    "    quartile3 = dataframe[variable].quantile(0.99)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "def check_outlier(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def grab_outliers(dataframe, col_name, index=False):\n",
    "    low, up = outlier_thresholds(dataframe, col_name)\n",
    "\n",
    "    if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:\n",
    "        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].head())\n",
    "    else:\n",
    "        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))])\n",
    "\n",
    "    if index:\n",
    "        outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].index\n",
    "        return outlier_index\n",
    "\n",
    "def replace_with_thresholds(dataframe, variable):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = round(low_limit, 0)\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = round(up_limit, 0)\n",
    "\n",
    "def remove_outlier(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    df_without_outliers = dataframe[~((dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]\n",
    "    return df_without_outliers\n",
    "\n",
    "def missing_values_table(dataframe, na_name=False):\n",
    "    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n",
    "    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n",
    "    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n",
    "    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n",
    "    print(missing_df, end=\"\\n\")\n",
    "    if na_name:\n",
    "        return na_columns\n",
    "\n",
    "def missing_vs_target(dataframe, target, na_columns):\n",
    "    temp_df = dataframe.copy()\n",
    "    for col in na_columns:\n",
    "        temp_df[col + '_NA_FLAG'] = np.where(temp_df[col].isnull(), 1, 0)\n",
    "    na_flags = temp_df.loc[:, temp_df.columns.str.contains(\"_NA_\")].columns\n",
    "    for col in na_flags:\n",
    "        print(pd.DataFrame({\"TARGET_MEAN\": temp_df.groupby(col)[target].mean(),\n",
    "                            \"Count\": temp_df.groupby(col)[target].count()}), end=\"\\n\\n\\n\")\n",
    "\n",
    "def one_hot_encoder(dataframe, categorical_cols, drop_first=True):\n",
    "    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n",
    "    return dataframe\n",
    "\n",
    "def rare_analyser(dataframe, target, cat_cols):\n",
    "    for col in cat_cols:\n",
    "        print(col, \":\", len(dataframe[col].value_counts()))\n",
    "        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n",
    "                            \"RATIO\": dataframe[col].value_counts() / len(dataframe),\n",
    "                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n",
    "\n",
    "def rare_encoder(dataframe, rare_perc):\n",
    "    temp_df = dataframe.copy()\n",
    "\n",
    "    rare_columns = [col for col in temp_df.columns if temp_df[col].dtypes == 'O'\n",
    "                    and (temp_df[col].value_counts() / len(temp_df) < rare_perc).any(axis=None)]\n",
    "\n",
    "    for var in rare_columns:\n",
    "        tmp = temp_df[var].value_counts() / len(temp_df)\n",
    "        rare_labels = tmp[tmp < rare_perc].index\n",
    "        temp_df[var] = np.where(temp_df[var].isin(rare_labels), 'Rare', temp_df[var])\n",
    "\n",
    "    return temp_df\n",
    "\n",
    "def check_skew(df_skew, column):\n",
    "    skew = stats.skew(df_skew[column])\n",
    "    skewtest = stats.skewtest(df_skew[column])\n",
    "    plt.title('Distribution of ' + column)\n",
    "    sns.distplot(df_skew[column], color=\"g\")\n",
    "    print(\"{}'s: Skew: {}, : {}\".format(column, skew, skewtest))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variable Information ##\n",
    "\n",
    "# CustomerId : Müşteri İd’si\n",
    "# Gender : Cinsiyet\n",
    "# SeniorCitizen : Müşterinin yaşlı olup olmadığı (1, 0)\n",
    "# Partner : Müşterinin bir ortağı olup olmadığı (Evet, Hayır) ? Evli olup olmama\n",
    "# Dependents : Müşterinin bakmakla yükümlü olduğu kişiler olup olmadığı (Evet, Hayır) (Çocuk, anne, baba, büyükanne)\n",
    "# tenure : Müşterinin şirkette kaldığı ay sayısı\n",
    "# PhoneService : Müşterinin telefon hizmeti olup olmadığı (Evet, Hayır)\n",
    "# MultipleLines : Müşterinin birden fazla hattı olup olmadığı (Evet, Hayır, Telefon hizmeti yok)\n",
    "# InternetService : Müşterinin internet servis sağlayıcısı (DSL, Fiber optik, Hayır)\n",
    "# OnlineSecurity : Müşterinin çevrimiçi güvenliğinin olup olmadığı (Evet, Hayır, İnternet hizmeti yok)\n",
    "# OnlineBackup : Müşterinin online yedeğinin olup olmadığı (Evet, Hayır, İnternet hizmeti yok)\n",
    "# DeviceProtection : Müşterinin cihaz korumasına sahip olup olmadığı (Evet, Hayır, İnternet hizmeti yok)\n",
    "# TechSupport : Müşterinin teknik destek alıp almadığı (Evet, Hayır, İnternet hizmeti yok)\n",
    "# StreamingTV : Müşterinin TV yayını olup olmadığı (Evet, Hayır, İnternet hizmeti yok) Müşterinin, bir üçüncü taraf sağlayıcıdan televizyon programları yayınlamak için İnternet hizmetini kullanıp kullanmadığını gösterir\n",
    "# StreamingMovies : Müşterinin film akışı olup olmadığı (Evet, Hayır, İnternet hizmeti yok) Müşterinin bir üçüncü taraf sağlayıcıdan film akışı yapmak için İnternet hizmetini kullanıp kullanmadığını gösterir\n",
    "# Contract : Müşterinin sözleşme süresi (Aydan aya, Bir yıl, İki yıl)\n",
    "# PaperlessBilling : Müşterinin kağıtsız faturası olup olmadığı (Evet, Hayır)\n",
    "# PaymentMethod : Müşterinin ödeme yöntemi (Elektronik çek, Posta çeki, Banka havalesi (otomatik), Kredi kartı (otomatik))\n",
    "# MonthlyCharges : Müşteriden aylık olarak tahsil edilen tutar\n",
    "# TotalCharges : Müşteriden tahsil edilen toplam tutar\n",
    "# Churn : Müşterinin kullanıp kullanmadığı (Evet veya Hayır) - Geçen ay veya çeyreklik içerisinde ayrılan müşteriler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba76016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "\n",
    "telco = pd.read_csv(\"Telco-Customer-Churn.csv\")\n",
    "\n",
    "df = telco.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24638633",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c054641",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total Charges should be numeric\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea19bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There is only 11 NA values, it is OK to drop them.\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96916f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Churn\"] = df[\"Churn\"].apply(lambda x: 1 if x == \"Yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec697e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dealing with imbalanced dataset:\n",
    "# I'll use bootstrapping but gotta respect the frequency difference between Churn levels\n",
    "## To avoid data leakage to testing, I'll not concatenate.\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, stratify=df.Churn, random_state=26)\n",
    "\n",
    "train_churned = train.loc[train[\"Churn\"] == 1, :]\n",
    "\n",
    "sampled_within = train_churned.sample(n=(4130-1495), replace=True, random_state=26)\n",
    "\n",
    "train_new = train.append(sampled_within, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd079e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining a function to create new column\n",
    "\n",
    "def pay_auto(x):\n",
    "    if x == \"Bank transfer (automatic)\":\n",
    "        return 1\n",
    "    elif x == \"Credit card (automatic)\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e57e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Is payment auto?\n",
    "train_new[\"IsPayAuto\"] = train_new.loc[:, \"PaymentMethod\"].apply(lambda x: pay_auto(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22823f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of services\n",
    "train_new[\"TotalServices\"] = (train_new[['PhoneService', 'InternetService', 'OnlineSecurity',\n",
    "                                       'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "                                       'StreamingTV', 'StreamingMovies']]== 'Yes').sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Any protection?\n",
    "train_new[\"NEW_noProt\"] = train_new.apply(lambda x: 1 if (x[\"OnlineBackup\"] != \"Yes\") or (x[\"DeviceProtection\"] != \"Yes\") or (x[\"TechSupport\"] != \"Yes\") else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping the redundant column\n",
    "\n",
    "train_new.drop(\"PhoneService\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074b8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_, num_, cat_but_car_ = grab_col_names(train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d8b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [col for col in train_new if train_new[col].dtypes == \"object\" and col not in cat_but_car_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbdd9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_cols = [\"StreamingMovies\", \"StreamingTV\", \"TechSupport\", \"DeviceProtection\", \"OnlineBackup\", \"OnlineSecurity\", \"InternetService\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda5623",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = one_hot_encoder(train_new, [col for col in train_new if str(col) not in manual_cols and str(col) in cat_cols], True)\n",
    "train_new = one_hot_encoder(train_new, manual_cols, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new.drop([col for col in train_new if str(col).endswith(\"No internet service\")], axis=1, inplace=True)\n",
    "train_new.drop(\"InternetService_No\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02de818",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"IsPayAuto\"] = test.loc[:, \"PaymentMethod\"].apply(lambda x: pay_auto(x))\n",
    "test[\"TotalServices\"] = (test[['PhoneService', 'InternetService', 'OnlineSecurity',\n",
    "                                       'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "                                       'StreamingTV', 'StreamingMovies']]== 'Yes').sum(axis=1)\n",
    "test[\"NEW_noProt\"] = test.apply(lambda x: 1 if (x[\"OnlineBackup\"] != \"Yes\") or (x[\"DeviceProtection\"] != \"Yes\") or (x[\"TechSupport\"] != \"Yes\") else 0, axis=1)\n",
    "test.drop(\"PhoneService\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556325db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_, num_, cat_but_car_ = grab_col_names(test)\n",
    "cat_cols = [col for col in test if test[col].dtypes == \"object\" and col not in cat_but_car_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e4db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = one_hot_encoder(test, [col for col in test if str(col) not in manual_cols and str(col) in cat_cols], True)\n",
    "test = one_hot_encoder(test, manual_cols, False)\n",
    "\n",
    "test.drop([col for col in test if str(col).endswith(\"No internet service\")], axis=1, inplace=True)\n",
    "test.drop(\"InternetService_No\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e42db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_new.drop([\"Churn\", \"customerID\"], axis=1)\n",
    "y = train_new[\"Churn\"]\n",
    "X_test = test.drop([\"Churn\", \"customerID\"], axis=1)\n",
    "y_test = test[\"Churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a5ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "\n",
    "lr_model = LogisticRegression(random_state=26, max_iter=1000, class_weight=\"balanced\").fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a322c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(lr_model,\n",
    "                           X, y,\n",
    "                           cv=5,\n",
    "                           scoring=[\"f1\", \"accuracy\", \"precision\", \"recall\", \"roc_auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_results[\"test_f1\"].mean())\n",
    "print(cv_results['test_accuracy'].mean())\n",
    "print(cv_results['test_precision'].mean())\n",
    "print(cv_results['test_recall'].mean())\n",
    "print(cv_results[\"test_roc_auc\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f9ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f08f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {round(accuracy_score(y_pred, y_test), 3)}\")\n",
    "print(f\"Recall: {round(recall_score(y_pred,y_test),3)}\")\n",
    "print(f\"Precision: {round(precision_score(y_pred,y_test), 3)}\")\n",
    "print(f\"F1: {round(f1_score(y_pred,y_test), 3)}\")\n",
    "print(f\"Auc: {round(roc_auc_score(y_pred,y_test), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d141f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "g = fig.add_subplot(1,1,1)\n",
    "plot_confusion_matrix(lr_model, X_test, y_test, ax=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51436da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04032a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To take a different approach towards imbalance of the data in respect to churn\n",
    "## we may change the class_weight accordingly and search through best values for F1 score\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, random_state=26)\n",
    "\n",
    "#Setting the range for class weights\n",
    "weights = np.linspace(0.0,0.99,200)\n",
    "\n",
    "#Creating a dictionary grid for grid search\n",
    "param_grid = {'class_weight': [{0:x, 1:1.0-x} for x in weights]}\n",
    "\n",
    "#Fitting grid search to the train data with 5 folds\n",
    "gridsearch = GridSearchCV(estimator= lr, \n",
    "                          param_grid= param_grid,\n",
    "                          cv=StratifiedKFold(), \n",
    "                          n_jobs=-1, \n",
    "                          scoring='f1', \n",
    "                          verbose=2).fit(X, y)\n",
    "\n",
    "#Ploting the score for different values of weight\n",
    "plt.figure(figsize=(12,8))\n",
    "weigh_data = pd.DataFrame({ 'score': gridsearch.cv_results_['mean_test_score'], 'weight': (1- weights)})\n",
    "sns.lineplot(weigh_data['weight'], weigh_data['score'])\n",
    "plt.xlabel('Weight for class 1')\n",
    "plt.ylabel('F1 score')\n",
    "plt.xticks([round(i/10,1) for i in range(0,11,1)])\n",
    "plt.title('Scoring for different class weights', fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4f246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Or, we can change class_weights manually and give more importance to churn\n",
    "## depending on the business approach\n",
    "\n",
    "#importing and training the model\n",
    "lr = LogisticRegression(max_iter=1000, random_state=26, class_weight={0: 0.25, 1: 0.75})\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Predicting on the test data\n",
    "pred_test = lr.predict(X_test)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "g = fig.add_subplot(1,1,1)\n",
    "plot_confusion_matrix(lr, X_test, y_test, ax=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0248fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=26, class_weight=\"balanced\").fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e65bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(lgbm, X, y, cv=5, scoring=[\"f1\", \"recall\", \"precision\", \"accuracy\", \"roc_auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6b5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_results[\"test_f1\"].mean())\n",
    "print(cv_results['test_accuracy'].mean())\n",
    "print(cv_results['test_precision'].mean())\n",
    "print(cv_results['test_recall'].mean())\n",
    "print(cv_results[\"test_roc_auc\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d49419",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd37cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {round(accuracy_score(y_pred, y_test), 3)}\")\n",
    "print(f\"Recall: {round(recall_score(y_pred,y_test),3)}\")\n",
    "print(f\"Precision: {round(precision_score(y_pred,y_test), 3)}\")\n",
    "print(f\"F1: {round(f1_score(y_pred,y_test), 3)}\")\n",
    "print(f\"Auc: {round(roc_auc_score(y_pred,y_test), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "g = fig.add_subplot(1,1,1)\n",
    "plot_confusion_matrix(lgbm, X_test, y_test, ax=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae53e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8393803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\"learning_rate\": [0.01, 0.1, 0.2],\n",
    "               \"n_estimators\": [2500, 3000, 3500, 4000],\n",
    "               \"colsample_bytree\": [0.3, 0.5, 0.7, 1]}\n",
    "\n",
    "# 300, 500, 800, 1000, 1500, 2000, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c81135",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_best_grid = GridSearchCV(lgbm,\n",
    "                              lgbm_params,\n",
    "                              cv=5,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=1).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_best_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391a4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_final = LGBMClassifier(**lgbm_best_grid.best_params_, random_state=26, class_weight=\"balanced\").fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee62d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4464c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {round(accuracy_score(y_pred, y_test), 3)}\")\n",
    "print(f\"Recall: {round(recall_score(y_pred,y_test),3)}\")\n",
    "print(f\"Precision: {round(precision_score(y_pred,y_test), 3)}\")\n",
    "print(f\"F1: {round(f1_score(y_pred,y_test), 3)}\")\n",
    "print(f\"Auc: {round(roc_auc_score(y_pred,y_test), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db416ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "g = fig.add_subplot(1,1,1)\n",
    "plot_confusion_matrix(lgbm_final, X_test, y_test, ax=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CatBoost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cb_model = CatBoostClassifier(random_state=26, verbose=False, auto_class_weights=\"Balanced\").fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a93592",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(cb_model, X, y, cv=5, scoring=[\"f1\", \"recall\", \"precision\", \"accuracy\", \"roc_auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f49448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_results[\"test_f1\"].mean())\n",
    "print(cv_results['test_accuracy'].mean())\n",
    "print(cv_results['test_precision'].mean())\n",
    "print(cv_results['test_recall'].mean())\n",
    "print(cv_results[\"test_roc_auc\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5584d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {round(accuracy_score(y_pred, y_test), 3)}\")\n",
    "print(f\"Recall: {round(recall_score(y_pred,y_test),3)}\")\n",
    "print(f\"Precision: {round(precision_score(y_pred,y_test), 3)}\")\n",
    "print(f\"F1: {round(f1_score(y_pred,y_test), 3)}\")\n",
    "print(f\"Auc: {round(roc_auc_score(y_pred,y_test), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc88b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_params = {\"iterations\": [500, 1000, 1500],\n",
    "             \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "             \"depth\": [3, 6, 8, 10, 15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af8dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_best_grid = GridSearchCV(cb_model,\n",
    "                            cb_params,\n",
    "                            cv=3,\n",
    "                            verbose=1).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65662e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_final = cb_model.set_params(**cb_best_grid.best_params_, random_state=26, verbose=False, auto_class_weights=\"Balanced\").fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cb_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2095bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {round(accuracy_score(y_pred, y_test), 3)}\")\n",
    "print(f\"Recall: {round(recall_score(y_pred,y_test),3)}\")\n",
    "print(f\"Precision: {round(precision_score(y_pred,y_test), 3)}\")\n",
    "print(f\"F1: {round(f1_score(y_pred,y_test), 3)}\")\n",
    "print(f\"Auc: {round(roc_auc_score(y_pred,y_test), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b214cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "g = fig.add_subplot(1,1,1)\n",
    "plot_confusion_matrix(cb_model, X_test, y_test, ax=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c14c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "g = fig.add_subplot(1,1,1)\n",
    "plot_confusion_matrix(cb_final, X_test, y_test, ax=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897a3e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4717033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(model, features, num=len(X), save=False):\n",
    "    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.set(font_scale=1)\n",
    "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",\n",
    "                                                                     ascending=False)[0:num])\n",
    "    plt.title('Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if save:\n",
    "        plt.savefig('importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797bdaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(cb_final, X_test, 10, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
